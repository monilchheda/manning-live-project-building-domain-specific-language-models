{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dsl-w2-ngrams.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOGDsXpbmYet+FDxGhbJgxi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/monilchheda/manning-live-project-building-domain-specific-language-models/blob/master/dsl_w2_ngrams.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ibhvf0eWkT7",
        "colab_type": "code",
        "outputId": "179d1fa4-0ab5-4720-cabb-904e57b38a29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "#https://github.com/zapidan/deep-learn-nlp/blob/3d411858905a2c091309af87634ab5dde592a869/notebooks/NGramLanguageModel.ipynb\n",
        "import pandas as pd\n",
        "df = pd.read_csv('https://liveproject-resources.s3.amazonaws.com/116/other/stackexchange_812k.csv.gz', compression='gzip')\n",
        "df.info()\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 812132 entries, 0 to 812131\n",
            "Data columns (total 5 columns):\n",
            " #   Column      Non-Null Count   Dtype  \n",
            "---  ------      --------------   -----  \n",
            " 0   post_id     812132 non-null  int64  \n",
            " 1   parent_id   75535 non-null   float64\n",
            " 2   comment_id  553076 non-null  float64\n",
            " 3   text        812132 non-null  object \n",
            " 4   category    812132 non-null  object \n",
            "dtypes: float64(2), int64(1), object(2)\n",
            "memory usage: 31.0+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07K7ZQZfXU5w",
        "colab_type": "text"
      },
      "source": [
        "Cleanup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGsNwJf-XWmC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        " \n",
        "# html tags\n",
        "df['text'] = df.text.apply(lambda t : re.sub(\"<[^>]*>\",' ', t))\n",
        "# line returns\n",
        "df['text'] = df.text.apply(lambda t : re.sub(\"[\\r\\n]+\",' ', t))\n",
        "# urls\n",
        "df['text'] = df.text.apply(lambda t : re.sub(\"http\\S+\",' ', t))\n",
        "# mentions\n",
        "df['text'] = df.text.apply(lambda t : re.sub(\"@\\S+\",' ', t))\n",
        "# latex\n",
        "df['text'] = df.text.apply(lambda t : re.sub(\"\\$[^>]*\\$\",' ', t))\n",
        "# digits\n",
        "df['text'] = df.text.apply(lambda t : re.sub(\"\\d+\",' ', t))\n",
        "# rm some of the punctuation but keep ,.!? and -\n",
        "punctuation = '\"#$%&()*+/:;<=>@[\\\\]^_`{|}~”“'\n",
        "pattern = r\"[{}]\".format(punctuation)\n",
        "df['text'] = df.text.apply(lambda t : re.sub(pattern,' ', t))\n",
        "# multiple spaces\n",
        "df['text'] = df.text.apply(lambda t : re.sub(\"\\s\\s+\",' ', t))\n",
        "# trailing spaces\n",
        "df['text'] = df.text.apply(lambda t : t.strip())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTpfR3JrXjKd",
        "colab_type": "text"
      },
      "source": [
        "Tokenize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fdL2Mb7XkQk",
        "colab_type": "code",
        "outputId": "fd278ba1-bb9b-47ca-e6fc-f6e3f279e213",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "source": [
        "\n",
        "from nltk.tokenize import WordPunctTokenizer\n",
        "\n",
        "tokenizer = WordPunctTokenizer()\n",
        "df['tokens'] = df.text.apply(lambda t : tokenizer.tokenize(t.lower()))\n",
        "\n",
        "\n",
        "# Add number of tokens\n",
        "df['n_tokens'] = df.tokens.apply(len)\n",
        "\n",
        "\n",
        "#df.head()\n",
        "\n",
        "\n",
        "df.sample(5).tokens.values\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([list(['wording', 'of', 'your', 'answer', 'could', 'be', 'misleading', '.', 'as', 'far', 'as', 'i', 'remember', ',', 'spss', 'uses', 'b', 'for', 'regression', 'parameter', 'and', 'beta', 'for', 'standarized', 'parameter', '.', 'on', 'another', 'hand', ',', 'r', 'uses', 'estimate', 'for', 'parameter', 'and', 't', 'value', 'for', 'standarized', 'parameter', '.', 'what', 'you', 'call', 't', 'stat', 'is', 'rather', 'a', 'statistic', 'see']),\n",
              "       list(['have', 'you', 'considered', 'looking', 'at', 'power', 'over', 'a', 'range', 'of', 'effect', 'sizes', '?', 'for', 'example', ',', 'i', 'frequently', 'calculate', 'power', 'as', 'a', 'curve', ',', 'and', 'end', 'up', 'with', 'a', 'myriad', 'of', 'potential', 'scenarios', 'baked', 'into', 'the', 'graph', ',', 'wherein', 'i', 'can', 'then', 'make', 'a', 'sample', 'size', 'decision', '.', 'for', 'example', ',', 'i', 'might', 'calculate', 'the', 'needed', 'sample', 'size', 'for', 'effect', 'measures', 'ranging', 'from', 'very', 'close', 'to', 'null', 'to', 'slightly', 'higher', 'than', 'my', 'wildest', ',', 'this', '-', 'will', '-', 'sail', '-', 'through', '-', 'peer', '-', 'review', 'dreams', '.', 'i', 'might', 'also', 'plot', 'other', 'scenarios', ',', 'depending', 'on', 'how', 'much', 'i', 'don', \"'\", 't', 'know', 'about', 'the', 'data', '.', 'for', 'example', ',', 'below', 'is', 'a', 'plot', 'that', 'calculates', 'power', ',', 'not', 'sample', 'size', ',', 'but', 'has', 'a', 'similar', 'concept', 'to', 'it', '.', 'i', 'know', 'very', 'little', 'about', 'the', 'data', ',', 'so', 'i', 'assumed', 'a', 'event', 'rate', 'for', 'a', 'survival', 'analysis', ',', 'and', 'then', 'calculated', 'the', 'study', \"'\", 's', 'power', 'sample', 'size', 'was', 'fixed', 'over', 'a', 'number', 'of', 'conditions', 'one', 'might', 'also', 'even', 'be', 'able', 'to', 'vary', 'in', 'this', 'case', 'the', 'number', 'of', 'events', ',', 'which', 'would', 'leave', 'you', 'with', 'either', 'multiple', 'plots', ',', 'or', 'a', 'power', 'surface', '.', 'that', 'seems', 'to', 'be', 'a', 'much', 'quicker', 'way', 'to', 'get', 'a', 'handle', 'on', 'at', 'least', 'where', 'you', 'should', 'be', 'looking', 'for', 'sample', 'size', ',', 'rather', 'than', 'modifying', 'sample', 'size', 'on', 'the', 'fly', '.', 'or', 'at', 'least', 'give', 'you', 'a', 'threshold', 'where', 'you', 'can', 'stop', 'adding', 'people', '.', 'for', 'example', ',', 'if', 'your', 'calculations', 'tell', 'you', ',', 'people', 'will', 'let', 'you', 'see', 'an', 'effect', 'of', 'something', 'very', 'small', '-', 'for', 'example', ',', 'a', 'hazard', 'ratio', 'of', '.', 'or', 'the', 'like', '-', 'you', 'know', 'that', 'if', 'you', 'hit', 'that', ',', 'you', 'can', 'stop', 'trying', 'to', 'add', 'people', ',', 'because', 'its', 'not', 'a', 'power', 'problem', ',', 'but', 'a', 'there', \"'\", 's', 'nothing', 'there', 'problem', '.']),\n",
              "       list(['since', 'my', 'comment', 'the', 'range', 'has', 'been', 'explained', 'as', 'from', '.', 'to', '.', '.', 'still', '.', 'my', 'hunch', 'remains', 'that', 'beta', 'regression', 'won', \"'\", 't', 'yield', 'much', 'better', 'fit', '.']),\n",
              "       list(['normalizing', 'logistic', 'regression', 'coefficients', '?']),\n",
              "       list(['i', 'am', 'trying', 'to', 'plot', 'a', 'two', '-', 'component', 'mixture', 'distribution', '.', 'i', 'have', 'done', 'the', 'histogram', 'for', 'it', 'but', 'having', 'trouble', 'with', 'plotting', 'the', 'true', 'density', ',', 'so', 'far', 'this', 'is', 'my', 'code', 'x', 'lt', '-', 'rep', 'na', ',', 'mu', 'lt', '-', 'sd', 'lt', '-', 'mu', 'lt', '-', 'sd', 'lt', '-', 'for', 'i', 'in', 'n', 'u', 'lt', '-', 'runif', ',', ',', 'if', 'u', 'lt', '.', 'x', 'i', 'lt', '-', 'rnorm', ',', 'mu', ',', 'sd', 'else', 'x', 'i', 'lt', '-', 'rnorm', ',', 'mu', ',', 'sd', 'hist', 'x', ',', 'prob', 't'])],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOHGzJYGZBYw",
        "colab_type": "text"
      },
      "source": [
        "Prepare test and train dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFwI0QlaZDkY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## https://stackoverflow.com/questions/24147278/how-do-i-create-test-and-train-samples-from-one-dataframe-with-pandas\n",
        "## Split titles per suggestion from Steven\n",
        "\n",
        "titledf = df[df.category == 'title'].copy()\n",
        "\n",
        "trainds=titledf.sample(frac=0.8,random_state=200) #random state is a seed value\n",
        "testds=titledf.drop(trainds.index)\n",
        "\n",
        "#testdf = df[df.category == 'title'].copy()\n",
        "#traindf = df[(df.category == 'post') | (df.category == 'comment')].copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrJdyI8fZ2HH",
        "colab_type": "text"
      },
      "source": [
        "prefix matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WIAHsJlZyWd",
        "colab_type": "code",
        "outputId": "e1945b2c-ec26-4967-eebe-040befaf5549",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from nltk.util import ngrams\n",
        "from collections import defaultdict, Counter\n",
        "\n",
        "counts = defaultdict(Counter)\n",
        "n = 3 # Trigrams\n",
        "\n",
        "for tokens in trainds.tokens.values:\n",
        "    for ngram in ngrams(\n",
        "            tokens,\n",
        "            n,\n",
        "            pad_left = True,\n",
        "            pad_right = True,\n",
        "            left_pad_symbol = \"<s>\",\n",
        "            right_pad_symbol=\"</s>\"):\n",
        "        \n",
        "        prefix = ngram[:n-1]\n",
        "        token = ngram[n-1]\n",
        "        counts[prefix][token] +=1\n",
        "\n",
        "\n",
        "print(\"bigrams count\", format(len(counts.keys())))\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bigrams count 185433\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pANLuG_tcC0h",
        "colab_type": "code",
        "outputId": "ef3fbd04-0bac-4b0a-9827-732856a5b075",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "import random\n",
        "for i in range(5):\n",
        "    prefix = random.choice(list(counts.keys()))\n",
        "    print(\"{}: \\t{}\".format(prefix,counts[prefix]))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('address', '</s>'): \tCounter({'</s>': 1})\n",
            "('descrete', 'values'): \tCounter({'in': 1})\n",
            "('represent', '?'): \tCounter({'</s>': 8})\n",
            "('column', 'elements'): \tCounter({'to': 1})\n",
            "('<s>', 'interpetation'): \tCounter({'of': 1})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgpMn_X4cuah",
        "colab_type": "text"
      },
      "source": [
        "Probabilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jVmGtaJcv3L",
        "colab_type": "code",
        "outputId": "83f05489-f3fb-45b7-eee5-1e1a14c35b9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "# probabilities\n",
        "\n",
        "frequencies = defaultdict(dict)\n",
        "\n",
        "for prefix, tokens in counts.items():\n",
        "    total_count = sum(tokens.values())\n",
        "    for token, count in tokens.items():\n",
        "        frequencies[prefix][token] = count / total_count\n",
        "\n",
        "\n",
        "for i in range(5):\n",
        "    prefix = random.choice(list(frequencies.keys()))\n",
        "    print(\"{}: \\t{}\".format(prefix,frequencies[prefix]))  \n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('length', 'data'): \t{'for': 1.0}\n",
            "('coefficient', 'b'): \t{'value': 0.5, 'for': 0.5}\n",
            "('for', 'feed'): \t{'forward': 1.0}\n",
            "('extra', 'explanatory'): \t{'variable': 1.0}\n",
            "('attention', 'mechanisms'): \t{'?': 1.0}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEQoEXTCdA3a",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Text Generation\n",
        "\n",
        "*   takes a bigram (must exist in corpus) as input\n",
        "*   generates a new token by sampling the available tokens related to the bigram using the frequency object as distribution\n",
        "*   slides the bigram to include the new token\n",
        "*   generates a new token based on the new bigram\n",
        "* stops when the text is N tokens long or the latest token is the end of string symbol\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rEQT8fCx2FB",
        "colab_type": "code",
        "outputId": "e4131a3e-c355-46d6-ac12-8a9ac3e33818",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "text = 'the model'\n",
        "\n",
        "prefix = text.split()[-3 + 1:]\n",
        "print (prefix)\n",
        "#prefix = tuple(text.split()[-n + 1:])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['the', 'model']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9ZOdf7WdVIl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def generate(text, n_tokens = 20):\n",
        "    for i in range(n_tokens):\n",
        "        prefix = tuple(text.split()[-n + 1:]) # n = 3 since we're looking at trigrams\n",
        "        #print (\"i --> \", i, prefix)\n",
        "        #break\n",
        "        if len(frequencies[prefix]) == 0: # next word is not loaded in the frequency dictionary\n",
        "            break\n",
        "        candidates = list(frequencies[prefix].keys()) # find tokens that could follow that prefix\n",
        "        #print (\"i candidates --> \", candidates)\n",
        "        probabilities = list(frequencies[prefix].values()) # find probabilities of tokens that can follow prefix\n",
        "        #print (\"i probs --> \", probabilities)\n",
        "        text += ' ' + np.random.choice(candidates, p = probabilities)\n",
        "        #print (text)\n",
        "        if text.endswith('</s>'):\n",
        "            break\n",
        "        i += 1\n",
        "\n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNSuQBW0ryVs",
        "colab_type": "code",
        "outputId": "804e2007-f95e-415f-acea-de6d47f362a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "text = 'data model'\n",
        "print()\n",
        "print(generate(text))\n",
        "\n",
        "print()\n",
        "text = 'that distribution'\n",
        "print(generate(text))\n",
        "\n",
        "print()\n",
        "text = 'to determine'\n",
        "print(generate(text))\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "data model with drift and a continuous dependent variable with variance equal to in elastic net coefficients are significant ? </s>\n",
            "\n",
            "that distribution ? </s>\n",
            "\n",
            "to determine if missing values </s>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjsLqjGP5uQC",
        "colab_type": "code",
        "outputId": "40dbce9f-bb0c-4fcf-d5e3-fae1d1a913ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "import math\n",
        "def get_probs(s):\n",
        "    if type(s) == str:\n",
        "        s = s.split(' ')    \n",
        "    probs  = []\n",
        "    tgrams = ngrams(s, 3,  pad_left=True, pad_right=True, left_pad_symbol='<s>', right_pad_symbol='</s>')\n",
        "    for tg in tgrams:\n",
        "        #print (tg)\n",
        "        bg = tg[:-1]\n",
        "        wd = tg[-1]\n",
        "        if not bg in frequencies:\n",
        "            probs.append(0)\n",
        "            #print (\"yes\")\n",
        "        else:\n",
        "            pb = frequencies[bg][wd] if wd in frequencies[bg] else 0\n",
        "            probs.append(pb)\n",
        "            #print (\"no\")\n",
        "            #print (probs)\n",
        "    return probs\n",
        "\n",
        "print (get_probs('the model'))\n",
        "\n",
        "def perplexity(s):\n",
        "    #steps\n",
        "    # * get probs for all trigrams.\n",
        "    # * calc 1/p for each\n",
        "    # * take the log of each \n",
        "    # * sum up the logs  \n",
        "    # * multiple the result by 1/(len(s)) \n",
        "    # * exp() the result. \n",
        "    lip = [math.log(1/p) for p in get_probs(s)]\n",
        "    N = len(lip)\n",
        "    return math.exp((1/N) * sum(lip))\n",
        "\n",
        "\n",
        "print (perplexity('the model'))    "
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.005217841475709108, 0.0026109660574412533, 0.1328125, 1.0]\n",
            "27.265736632130398\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pv_Pk6fHJB2J",
        "colab_type": "text"
      },
      "source": [
        "Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkbF3LppJACz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prepare the training data\n",
        "#!pip install nltk --upgrade\n",
        "import nltk\n",
        "import nltk.lm\n",
        "from nltk.lm.preprocessing import padded_everygram_pipeline \n",
        "from nltk.lm import MLE\n",
        "from nltk.lm import Vocabulary\n",
        "from nltk.util import ngrams\n",
        "\n",
        "\n",
        "ngrams_degree = 3\n",
        "\n",
        "# train_data = [\n",
        "#     ngrams(t, n= ngrams_degree,\n",
        "#         pad_right=True, pad_left=True,\n",
        "#         left_pad_symbol=\"<s>\", right_pad_symbol=\"</s>\")\n",
        "#     for t in df_train.tokens.values]\n",
        "\n",
        "# words = [word for sent in df_train.tokens.values for word in sent]\n",
        "# words.extend([\"<s>\", \"</s>\"])\n",
        "train, vocab = padded_everygram_pipeline(ngrams_degree, trainds.tokens)\n",
        "# vocab = Vocabulary(words, unk_cutoff = 20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjVwbzX8pAY_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define the model\n",
        "model = MLE(ngrams_degree)\n",
        "# print(len(model.vocab))\n",
        "\n",
        "# fit the model\n",
        "model.fit(train, vocab)\n",
        "# print(len(model.vocab))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHOkiq0TpYzk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "bba9b825-f2c9-4e73-a203-ee8811d4f8eb"
      },
      "source": [
        "print(model.vocab.lookup([\"aliens\", \"from\", \"Mars\"]))\n",
        "print(model.counts)\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('<UNK>', '<UNK>', '<UNK>')\n",
            "<NgramCounter with 3 ngram orders and 2818740 ngrams>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74vH0ejbpcs-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2cafeaab-2b43-44fd-b2f3-18023ffeda30"
      },
      "source": [
        "model.score(\"has\", [\"the\", \"model\"])\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57gFx_o3pgdo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "781dba22-218e-4849-f5fc-40f3c8ef97d3"
      },
      "source": [
        "test = \"the difference between the two approaches is discussed here.\"\n",
        "model.perplexity(test)\n",
        "test = \"the difference between the two approaches is discussed here\"\n",
        "model.perplexity(test)\n",
        "test = \"the difference between the two approaches\"\n",
        "model.perplexity(test)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0NiitJOqwVW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f640a01c-0290-4f5e-981f-173b12738377"
      },
      "source": [
        "model.generate(2, random_seed=3)\n",
        "# not sure why its not working"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<UNK>', '<UNK>']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    }
  ]
}